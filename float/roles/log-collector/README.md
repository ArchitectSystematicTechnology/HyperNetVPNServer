Logging overview
===

This document explains how logging works in this infrastructure.

Logs are forwarded by all machines to a set of (one or more)
*log-collector* instances. These log-collector instances receive logs
over syslog/tcp (with SSL) and store them locally for search and
aggregation purposes.

## Log types

There are three main log types at the moment, though more might be
added:

* Standard *syslog logs*
* *HTTP logs*, generated in a specific format (an extension of the
  Apache Combined Log format) by our NGINX front-ends, which use the
  syslog facility *local3*, exclusively dedicated to this purpose
* *structured logs*, which are generated by applications
  in
  [CEE/lumberjack format](https://www.rsyslog.com/doc/v8-stable/configuration/modules/mmjsonparse.html) (simply
  a JSON dictionary prepended by the literal string `@cee:`).

## Log processing

Syslog logs received by the log-collector will be subject to further
processing in order to extract metadata fields that will be stored and
indexed.

The implementation uses
the
[mmnormalize](https://www.rsyslog.com/doc/v8-stable/configuration/modules/mmnormalize.html) rsyslog
module, which parses logs using
the [liblognorm](http://www.liblognorm.com/files/manual/index.html)
engine to extract metadata fields.

Liblognorm rulebase files are a bit verbose but relatively simple to
write. Rules can be manually tested using the *lognormalizer* utility,
part of the *liblognorm-utils* Debian package. Rules should be placed
in the roles/log-collector/files/lognorm directory.

## Technical implementation details

The logging stack on each individual machine looks like the following:

* The local *rsyslogd* collects logs from the systemd journal and the
  default syslog socket, and sends logs to the centralized log
  collectors.
* It also runs a *mtail* instance on the local log stream, scraped by
  the monitoring system, allowing us to derive custom metrics from
  logs.

The log-collector instances run a minimalistic ELK-like stack, where
Logstash has been removed and its functionality reproduced in rsyslogd
itself:

* A separate instance of *rsyslogd* named *rsyslog-collector* listens
  for incoming logs on port 6514 (the standard syslog-tls service),
  and forwards logs, after some processing, to Elasticsearch.
* Elasticsearch stores logs on the local disk.
* Kibana is used to provide a query front-end to the archived logs.

The structure of Elasticsearch indexes match what would have been
produced by Logstash, with daily *logstash-YYYY.MM.DD* indexes. HTTP
logs use a separate set of indexes, with a similar structure but a
*http-* prefix.

We use Elasticsearch index templates (in
roles/log-collector/templates/elasticsearch/templates) to optimize the
schema a bit, disabling indexing on problematic fields, and setting
sane replication options.

## Adding applications

Further application-specific indexing can be configured (for example,
audit logs) by adding the appropriate filters in
`rsyslog-collector.conf`, sending data to different Elasticsearch
indexes.

## Dashboard provisioning

Kibana is the availabile UI and its dashboards are sourced from
`roles/log-collector/files/kibana/provisioning`.

To add a new dashboard, or update an existing one, use Kibana's dashboard API
to download the dashboard and its related visualizations. The API is available
at `/api/kibana/dashboards/export?dashboard=DASHBOARD_ID`.
